{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/MyDrive/Colab Notebooks/ALD\n",
        "%ls"
      ],
      "metadata": {
        "id": "okwMeQ6x-Nmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c10c55-f474-47f3-902d-f4705946b832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/ALD'\n",
            "/content/drive/MyDrive/Colab Notebooks/ALD\n",
            "\u001b[0m\u001b[01;34mdatasets\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaC3RNGb99bu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = 'datasets/Accelerometer Data + TAC/'\n",
        "datasets = {filename.split('.')[0]: pd.read_csv(f'{DATASET_PATH}feature_data/{filename}') for filename in os.listdir(f'{DATASET_PATH}feature_data/')}"
      ],
      "metadata": {
        "id": "Qo_Lu9kaEdf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_len = 0\n",
        "toxicated = 0\n",
        "intoxicated = 0\n",
        "for dataset in datasets.values():\n",
        "    total_len += len(dataset)\n",
        "    intoxicated += sum(dataset['ground_truth'])\n",
        "toxicated = total_len - intoxicated\n",
        "\n",
        "print(f'Total number of samples: {total_len}')\n",
        "print(f'toxicated: {toxicated}')\n",
        "print(f'intoxicated: {intoxicated}')"
      ],
      "metadata": {
        "id": "02VHPbD4HblT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0f81fb-f15b-47ab-c428-d98e09346d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples: 35860\n",
            "toxicated: 16672\n",
            "intoxicated: 19188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets[list(datasets.keys())[0]].head()"
      ],
      "metadata": {
        "id": "UTWO-c9iEkg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "3d8ac508-5fd5-435e-8f16-f4d51b06b0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   x_mean_mean  x_mean_variance  x_mean_min  x_mean_max  \\\n",
              "0     0.013721     7.599049e-04   -0.017745    0.070992   \n",
              "1     0.002651     2.973126e-05   -0.002529    0.014274   \n",
              "2     0.000887     9.807391e-06   -0.002924    0.007199   \n",
              "3    -0.000514     2.979465e-06   -0.004895    0.000923   \n",
              "4     0.000993     2.941775e-07   -0.000308    0.002049   \n",
              "\n",
              "   x_mean_lower_third_mean  x_mean_upper_third_mean  y_mean_mean  \\\n",
              "0                -0.009408                 0.023633     0.000898   \n",
              "1                -0.002195                 0.004728     0.005218   \n",
              "2                -0.002314                 0.002259     0.003658   \n",
              "3                -0.002582                 0.000373     0.002559   \n",
              "4                 0.000487                 0.001210     0.001876   \n",
              "\n",
              "   y_mean_variance  y_mean_min  y_mean_max  ...  y_max_freq_max_diff  \\\n",
              "0         0.000027   -0.010774    0.009670  ...                 17.0   \n",
              "1         0.000027   -0.001043    0.015194  ...                  2.5   \n",
              "2         0.000008   -0.000531    0.009664  ...                  0.0   \n",
              "3         0.000019   -0.002534    0.014478  ...                 -0.5   \n",
              "4         0.000007   -0.001435    0.009453  ...                  0.5   \n",
              "\n",
              "   y_max_freq_lower_third_mean_diff  y_max_freq_upper_third_mean_diff  \\\n",
              "0                          3.166667                          9.857143   \n",
              "1                          0.333333                          3.071429   \n",
              "2                         -0.666667                          1.684211   \n",
              "3                         -2.491453                         -5.147983   \n",
              "4                          1.491453                          3.892343   \n",
              "\n",
              "   z_max_freq_mean_diff  z_max_freq_variance_diff  z_max_freq_min_diff  \\\n",
              "0             10.750000                 45.562500                  0.0   \n",
              "1              0.200000                -14.590000                  3.0   \n",
              "2             -1.478947                 14.995568                 -3.0   \n",
              "3             -1.744755                  3.987999                  0.0   \n",
              "4             -1.526298                 -4.346067                  0.0   \n",
              "\n",
              "   z_max_freq_max_diff  z_max_freq_lower_third_mean_diff  \\\n",
              "0                 19.5                          2.833333   \n",
              "1                  0.0                          1.500000   \n",
              "2                 -1.5                         -3.666667   \n",
              "3                  1.5                          0.683761   \n",
              "4                 -1.5                         -1.183761   \n",
              "\n",
              "   z_max_freq_upper_third_mean_diff  ground_truth  \n",
              "0                         14.142857             1  \n",
              "1                         -0.357143             1  \n",
              "2                         -0.541353             1  \n",
              "3                         -2.785547             1  \n",
              "4                         -1.673099             1  \n",
              "\n",
              "[5 rows x 757 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc4f7b7b-f521-43d7-9fda-03e805e909d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_mean_mean</th>\n",
              "      <th>x_mean_variance</th>\n",
              "      <th>x_mean_min</th>\n",
              "      <th>x_mean_max</th>\n",
              "      <th>x_mean_lower_third_mean</th>\n",
              "      <th>x_mean_upper_third_mean</th>\n",
              "      <th>y_mean_mean</th>\n",
              "      <th>y_mean_variance</th>\n",
              "      <th>y_mean_min</th>\n",
              "      <th>y_mean_max</th>\n",
              "      <th>...</th>\n",
              "      <th>y_max_freq_max_diff</th>\n",
              "      <th>y_max_freq_lower_third_mean_diff</th>\n",
              "      <th>y_max_freq_upper_third_mean_diff</th>\n",
              "      <th>z_max_freq_mean_diff</th>\n",
              "      <th>z_max_freq_variance_diff</th>\n",
              "      <th>z_max_freq_min_diff</th>\n",
              "      <th>z_max_freq_max_diff</th>\n",
              "      <th>z_max_freq_lower_third_mean_diff</th>\n",
              "      <th>z_max_freq_upper_third_mean_diff</th>\n",
              "      <th>ground_truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013721</td>\n",
              "      <td>7.599049e-04</td>\n",
              "      <td>-0.017745</td>\n",
              "      <td>0.070992</td>\n",
              "      <td>-0.009408</td>\n",
              "      <td>0.023633</td>\n",
              "      <td>0.000898</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>-0.010774</td>\n",
              "      <td>0.009670</td>\n",
              "      <td>...</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.166667</td>\n",
              "      <td>9.857143</td>\n",
              "      <td>10.750000</td>\n",
              "      <td>45.562500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.5</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>14.142857</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002651</td>\n",
              "      <td>2.973126e-05</td>\n",
              "      <td>-0.002529</td>\n",
              "      <td>0.014274</td>\n",
              "      <td>-0.002195</td>\n",
              "      <td>0.004728</td>\n",
              "      <td>0.005218</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>-0.001043</td>\n",
              "      <td>0.015194</td>\n",
              "      <td>...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3.071429</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-14.590000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>-0.357143</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000887</td>\n",
              "      <td>9.807391e-06</td>\n",
              "      <td>-0.002924</td>\n",
              "      <td>0.007199</td>\n",
              "      <td>-0.002314</td>\n",
              "      <td>0.002259</td>\n",
              "      <td>0.003658</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>0.009664</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>1.684211</td>\n",
              "      <td>-1.478947</td>\n",
              "      <td>14.995568</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-3.666667</td>\n",
              "      <td>-0.541353</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.000514</td>\n",
              "      <td>2.979465e-06</td>\n",
              "      <td>-0.004895</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>-0.002582</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.002559</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>-0.002534</td>\n",
              "      <td>0.014478</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>-2.491453</td>\n",
              "      <td>-5.147983</td>\n",
              "      <td>-1.744755</td>\n",
              "      <td>3.987999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.683761</td>\n",
              "      <td>-2.785547</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000993</td>\n",
              "      <td>2.941775e-07</td>\n",
              "      <td>-0.000308</td>\n",
              "      <td>0.002049</td>\n",
              "      <td>0.000487</td>\n",
              "      <td>0.001210</td>\n",
              "      <td>0.001876</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-0.001435</td>\n",
              "      <td>0.009453</td>\n",
              "      <td>...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.491453</td>\n",
              "      <td>3.892343</td>\n",
              "      <td>-1.526298</td>\n",
              "      <td>-4.346067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>-1.183761</td>\n",
              "      <td>-1.673099</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 757 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc4f7b7b-f521-43d7-9fda-03e805e909d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc4f7b7b-f521-43d7-9fda-03e805e909d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc4f7b7b-f521-43d7-9fda-03e805e909d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data, y_data = [], []\n",
        "\n",
        "for dataset in datasets.values():\n",
        "    dataset = dataset.dropna()\n",
        "    X_data.extend(dataset.iloc[:, :-1].values)\n",
        "    y_data.extend(dataset.iloc[:, -1].values)\n",
        "\n",
        "X_data = np.array(X_data)\n",
        "y_data = np.array(y_data)"
      ],
      "metadata": {
        "id": "MH24Xj-5Ep_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling Feature Data"
      ],
      "metadata": {
        "id": "PDbp8zwL_CJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_data)\n",
        "X_data = scaler.transform(X_data)"
      ],
      "metadata": {
        "id": "ip4hqN1CCC1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "Splitting the dataset into the Training set and Test set"
      ],
      "metadata": {
        "id": "IHMlIz0vNKc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')"
      ],
      "metadata": {
        "id": "aF6sjzWdNTx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c977dd-4cfe-490c-f1b6-fc6a305697f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (28362, 756)\n",
            "X_test shape: (7091, 756)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier"
      ],
      "metadata": {
        "id": "hG-TppdEIIjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iHOTDbC6NZs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "468e9800-4890-4ca1-ae0a-e9ad4f2112f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')"
      ],
      "metadata": {
        "id": "I4KKye7eNcyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c4cc80-a7e3-4ad5-f916-f4c7c5b6fb49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8901424340713581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10)"
      ],
      "metadata": {
        "id": "0bOq6iRXHk9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Naive Bayes\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FXkF_MW42e5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "response_values  = []\n",
        "for train_index, test_index in kf.split(X_data):\n",
        "  x_test, x_train = X_data[test_index], X_data[train_index]\n",
        "  y_test, y_train = y_data[test_index], y_data[train_index]\n",
        "  clf = GaussianNB()\n",
        "  clf.fit(x_train, y_train)\n",
        "  acc = accuracy_score(y_test, clf.predict(x_test))\n",
        "  response_values.append(acc)\n",
        "  print('Accuracy GNBClassifier ',acc)\n",
        "print('Avg Accuracy ',np.mean(response_values))"
      ],
      "metadata": {
        "id": "muz68MKz3EdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8917759-dfb8-4115-91d2-9278dcf51d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy GNBClassifier  0.0005640157924421884\n",
            "Accuracy GNBClassifier  0.2098138747884941\n",
            "Accuracy GNBClassifier  0.6604624929498026\n",
            "Accuracy GNBClassifier  0.6741889985895627\n",
            "Accuracy GNBClassifier  0.7447108603667136\n",
            "Accuracy GNBClassifier  0.7808180535966149\n",
            "Accuracy GNBClassifier  0.02538787023977433\n",
            "Accuracy GNBClassifier  0.8736248236953456\n",
            "Accuracy GNBClassifier  0.6104372355430183\n",
            "Accuracy GNBClassifier  0.5320169252468265\n",
            "Avg Accuracy  0.5112025150808595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "DqocPxZl3hMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "response_values  = []\n",
        "for train_index, test_index in kf.split(X_data):\n",
        "  x_test, x_train = X_data[test_index], X_data[train_index]\n",
        "  y_test, y_train = y_data[test_index], y_data[train_index]\n",
        "  clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
        "  clf.fit(x_train, y_train)\n",
        "  acc = accuracy_score(y_test, clf.predict(x_test))\n",
        "  response_values.append(acc)\n",
        "  print('Accuracy SGDClassifier ',acc)\n",
        "print('Avg Accuracy ',np.mean(response_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc64sMWP3p2j",
        "outputId": "134b7c1c-2a74-44b6-a69e-bf01f44c66a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy SGDClassifier  0.733784545967287\n",
            "Accuracy SGDClassifier  0.45346869712351945\n",
            "Accuracy SGDClassifier  0.6049069373942471\n",
            "Accuracy SGDClassifier  0.7187588152327221\n",
            "Accuracy SGDClassifier  0.86262341325811\n",
            "Accuracy SGDClassifier  0.7997179125528914\n",
            "Accuracy SGDClassifier  0.8586741889985896\n",
            "Accuracy SGDClassifier  0.5021156558533145\n",
            "Accuracy SGDClassifier  0.5571227080394923\n",
            "Accuracy SGDClassifier  0.9283497884344146\n",
            "Avg Accuracy  0.7019522662854588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COMPARISON"
      ],
      "metadata": {
        "id": "Gnokr6NtO4jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "05Dr9Cqa8Deb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare configuration for cross validation test harness\n",
        "# seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "# models.append(('RFC', RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "# models.append(('SVM', SVC()))\n",
        "\n",
        "\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        " kfold = KFold(n_splits=10)\n",
        " cv_results = cross_val_score(model, X_data, y_data, cv=kfold, scoring=scoring)\n",
        " results.append(cv_results)\n",
        " names.append(name)\n",
        "\n",
        "\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MaFND9tX7lHt",
        "outputId": "656f5e58-f642-4e3a-ac22-9f009b0ac777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(names)):\n",
        "  print(names[i], cv_results[i])"
      ],
      "metadata": {
        "id": "S2VoEaoPRPkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57a78f3-db44-4f95-c415-3c554f05e855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NB 0.7670614777213762\n",
            "LR 0.5462492949802594\n",
            "KNN 0.43542019176536945\n",
            "LDA 0.786459802538787\n"
          ]
        }
      ]
    }
  ]
}